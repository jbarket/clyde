<!-- Generated by clyde v1.0.0 on 2025-07-30 11:02:40 -->
<!-- Shared Content -->
<!-- Config Hash: ca424fbc -->

# Problem Solving

This file contains shared development standards used by all AI targets.

**⚠ Do not edit this file directly.** Changes will be overwritten.

- To modify standards: Edit `.clyde/config.yaml` and run `clyde sync`

# Cognitive Framework for Complex Problem Solving

## Core Principle

A cognitive framework provides structured mental models and thinking patterns that enhance problem-solving capabilities by leveraging different cognitive approaches based on context and complexity.

## When to Apply

- Complex problems requiring multiple perspectives
- Situations where domain expertise is critical
- When creative and analytical thinking must be balanced
- Multi-stakeholder problems with competing priorities
- Technical decisions with significant long-term impact

## Cognitive Archetypes

### The Architect
**Mental Model**: Systems thinking and long-term vision
- Focus on structure, relationships, and scalability
- Consider future evolution and maintenance
- Balance competing technical and business requirements
- Think in terms of patterns and abstractions

**When to Apply**: System design, technology strategy, complex refactoring

### The Analyst
**Mental Model**: Data-driven investigation and logical reasoning
- Break problems into measurable components
- Seek empirical evidence for decisions
- Identify patterns in data and behavior
- Question assumptions with systematic inquiry

**When to Apply**: Performance optimization, debugging, requirements analysis

### The Creator
**Mental Model**: Innovative solution generation
- Explore unconventional approaches
- Combine existing concepts in new ways
- Prototype and experiment rapidly
- Embrace acceptable risk for breakthrough solutions

**When to Apply**: New feature development, solving novel problems, overcoming technical limitations

### The Optimizer
**Mental Model**: Efficiency and continuous improvement
- Focus on eliminating waste and bottlenecks
- Measure and iterate systematically
- Consider resource constraints and trade-offs
- Prioritize high-impact, low-effort improvements

**When to Apply**: Code optimization, process improvement, resource allocation

### The Guardian
**Mental Model**: Risk assessment and quality assurance
- Anticipate failure modes and edge cases
- Ensure security, reliability, and compliance
- Plan for disaster recovery and maintenance
- Balance safety with progress

**When to Apply**: Security reviews, testing strategy, production deployments

## Framework Application Process

### 1. Context Assessment
```
Questions to ask:
- What type of problem am I solving?
- What are the stakes and constraints?
- What expertise is most relevant?
- What perspective might I be missing?
```

### 2. Archetype Selection
- Choose primary archetype based on problem type
- Identify secondary perspectives that add value
- Consider switching archetypes as understanding evolves
- Use multiple archetypes for complex, multi-faceted problems

### 3. Perspective Integration
- Apply each selected archetype's mental model
- Look for conflicts and synergies between perspectives
- Synthesize insights into coherent approach
- Document reasoning from each perspective

## Examples

### Problem: Database Performance Issues

**Architect Perspective**:
- Is this a fundamental design problem?
- Should we consider different data models?
- How will this scale with future growth?
- What are the architectural trade-offs?

**Analyst Perspective**:
- What does the profiling data tell us?
- Which queries are slowest and why?
- What are the usage patterns?
- Are there measurable bottlenecks?

**Optimizer Perspective**:
- Which improvements give biggest impact?
- What's the cost/benefit of each solution?
- Can we optimize existing queries first?
- What's the minimum viable improvement?

**Guardian Perspective**:
- Will optimization changes affect data consistency?
- Are there security implications?
- What's our rollback plan?
- How will we monitor the changes?

### Problem: Feature Development Priority

**Creator Perspective**:
- What innovative solutions could differentiate us?
- Are there unexplored user needs we could address?
- What would a breakthrough solution look like?

**Analyst Perspective**:
- What does user data tell us about priorities?
- Which features drive engagement/retention?
- What are the measurable business impacts?

**Optimizer Perspective**:
- Which features can be built most efficiently?
- What's the development ROI for each option?
- Can we leverage existing components?

**Guardian Perspective**:
- What are the risks of each approach?
- Which features might introduce technical debt?
- What's our capacity for maintenance?

## Cognitive Switching Techniques

### Perspective Rotation
Deliberately cycle through different archetypes:
1. Spend 10 minutes thinking as Architect
2. Switch to Analyst for data-driven view
3. Apply Creator mindset for innovative options
4. Use Guardian lens for risk assessment
5. Synthesize insights from all perspectives

### Devil's Advocate
For each archetype, ask:
- "What would [Archetype] be most concerned about?"
- "What might [Archetype] see that others miss?"
- "How would [Archetype] approach this differently?"

### Constraint Reframing
- **Architect**: What if we had unlimited time?
- **Analyst**: What if we had perfect data?
- **Creator**: What if there were no technical limitations?
- **Optimizer**: What if resources were extremely limited?
- **Guardian**: What if failure was unacceptable?

## Anti-patterns to Avoid

- **Single Archetype Bias**: Over-relying on your natural thinking style
- **Archetype Switching Too Fast**: Not spending enough time in each perspective
- **Perspective Paralysis**: Getting stuck trying to satisfy all viewpoints perfectly
- **Archetype Stereotyping**: Assuming archetypes are mutually exclusive
- **Context Ignorance**: Applying wrong archetype to situation

## Integration Benefits

- **Broader Solution Space**: Multiple perspectives reveal more options
- **Reduced Blind Spots**: Different archetypes catch different risks and opportunities
- **Better Stakeholder Communication**: Match communication style to audience perspective
- **Enhanced Team Collaboration**: Understand and leverage team members' natural thinking styles
- **More Robust Decisions**: Solutions that satisfy multiple valid perspectives are more likely to succeed

## Development Considerations

- Practice switching between archetypes consciously
- Develop comfort with each thinking style
- Learn to recognize which archetype a situation calls for
- Build teams with complementary cognitive strengths
- Create processes that engage multiple perspectives systematically

# Error Handling Philosophy

## Core Principle

Robust error handling involves anticipating failure modes, designing graceful degradation strategies, and providing clear feedback that enables appropriate responses from users and systems.

## When to Apply

- Input validation and boundary checking
- External system integrations (APIs, databases, file systems)
- Resource allocation and management  
- User-facing operations that may fail
- Background processes and async operations
- System startup and configuration loading

## Error Handling Strategies

### 1. Fail Fast
Detect and report errors as early as possible:
- **Input Validation**: Verify inputs at system boundaries
- **Configuration Validation**: Check settings at startup
- **Precondition Checks**: Validate assumptions before processing
- **Type Safety**: Use type systems to catch errors at compile time

### 2. Graceful Degradation
Continue operating with reduced functionality when possible:
- **Feature Toggling**: Disable non-critical features when dependencies fail
- **Fallback Mechanisms**: Provide alternative implementations
- **Caching**: Use cached data when live data unavailable
- **Default Values**: Provide sensible defaults when configuration fails

### 3. Error Recovery
Attempt to recover from transient failures:
- **Retry Logic**: Implement exponential backoff for transient failures
- **Circuit Breakers**: Prevent cascading failures
- **Timeouts**: Avoid hanging on unresponsive operations
- **Cleanup**: Ensure proper resource cleanup on failure

## Error Classification

### 1. User Errors
Mistakes made by users that should be handled gracefully:
```python
class ValidationError(Exception):
    """Raised when user input fails validation."""
    def __init__(self, field: str, message: str):
        self.field = field
        self.message = message
        super().__init__(f"Validation failed for {field}: {message}")

def validate_email(email: str) -> str:
    """Validate email format and return normalized version."""
    if not email:
        raise ValidationError("email", "Email address is required")
    
    if "@" not in email:
        raise ValidationError("email", "Email address must contain @ symbol")
        
    return email.lower().strip()
```

### 2. System Errors
Infrastructure or dependency failures:
```python
class ExternalServiceError(Exception):
    """Raised when external service calls fail."""
    def __init__(self, service: str, operation: str, cause: Exception):
        self.service = service
        self.operation = operation
        self.cause = cause
        super().__init__(f"Failed to {operation} via {service}: {cause}")

def fetch_user_data(user_id: str) -> dict:
    """Fetch user data with proper error handling."""
    try:
        response = external_api.get_user(user_id)
        return response.json()
    except requests.ConnectionError as e:
        raise ExternalServiceError("user_api", "fetch_user", e)
    except requests.Timeout as e:
        raise ExternalServiceError("user_api", "fetch_user", e)
```

### 3. Programming Errors
Bugs that indicate code defects:
```python
def calculate_average(numbers: List[float]) -> float:
    """Calculate arithmetic mean of numbers."""
    assert numbers, "Cannot calculate average of empty list"
    assert all(isinstance(n, (int, float)) for n in numbers), "All items must be numeric"
    
    return sum(numbers) / len(numbers)
```

## Implementation Patterns

### Error Context
Provide sufficient information for debugging and user feedback:
```python
class PaymentError(Exception):
    """Base class for payment-related errors."""
    def __init__(self, message: str, error_code: str, context: dict = None):
        self.message = message
        self.error_code = error_code
        self.context = context or {}
        super().__init__(message)

def process_payment(amount: float, payment_method: str) -> str:
    """Process payment and return transaction ID."""
    context = {
        "amount": amount,
        "payment_method": payment_method,
        "timestamp": datetime.utcnow().isoformat(),
        "user_id": get_current_user_id()
    }
    
    try:
        transaction_id = payment_gateway.charge(amount, payment_method)
        return transaction_id
    except PaymentGatewayError as e:
        raise PaymentError(
            message="Payment processing failed",
            error_code="PAYMENT_GATEWAY_ERROR",
            context={**context, "gateway_error": str(e)}
        )
```

### Resource Management
Ensure proper cleanup even when errors occur:
```python
from contextlib import contextmanager

@contextmanager
def database_transaction():
    """Context manager for database transactions with proper cleanup."""
    connection = None
    try:
        connection = get_database_connection()
        connection.begin()
        yield connection
        connection.commit()
    except Exception as e:
        if connection:
            connection.rollback()
        raise
    finally:
        if connection:
            connection.close()
```

### Retry Logic
Handle transient failures with exponential backoff:
```python
import time
import random

def retry_with_backoff(
    func: Callable[[], T],
    max_attempts: int = 3,
    base_delay: float = 1.0,
    max_delay: float = 60.0,
    exceptions: tuple = (Exception,)
) -> T:
    """Retry function with exponential backoff."""
    for attempt in range(max_attempts):
        try:
            return func()
        except exceptions as e:
            if attempt == max_attempts - 1:
                raise  # Re-raise on final attempt
                
            delay = min(base_delay * (2 ** attempt), max_delay)
            jitter = delay * 0.1 * random.random()  # Add 10% jitter
            time.sleep(delay + jitter)
```

## Error Communication

### User-Friendly Messages
Translate technical errors into actionable user feedback:
```python
def format_user_error(error: Exception) -> dict:
    """Convert exceptions to user-friendly error responses."""
    if isinstance(error, ValidationError):
        return {
            "error_type": "validation_error",
            "message": f"Please check your {error.field}: {error.message}",
            "field": error.field,
            "code": "VALIDATION_FAILED"
        }
    elif isinstance(error, ExternalServiceError):
        return {
            "error_type": "service_error",
            "message": "We're experiencing technical difficulties. Please try again later.",
            "code": "SERVICE_UNAVAILABLE"
        }
    else:
        return {
            "error_type": "internal_error",
            "message": "An unexpected error occurred. Please contact support.",
            "code": "INTERNAL_ERROR"
        }
```

### Logging Strategy
Provide different levels of detail for different audiences:
```python
def log_error(error: Exception, context: dict = None):
    """Log errors with appropriate detail level."""
    context = context or {}
    
    # Always log basic error info
    logging.error(f"Error occurred: {type(error).__name__}: {error}")
    
    # Log context for debugging
    if context:
        logging.error(f"Error context: {context}")
    
    # Log full traceback for debugging
    logging.debug(f"Full traceback: {traceback.format_exc()}")
    
    # Log to external monitoring system
    if should_report_to_monitoring(error):
        monitoring_system.report_error(error, context)
```

## Testing Error Conditions

### Error Scenario Testing
```python
import pytest
from unittest.mock import patch

def test_payment_processing_network_error():
    """Test payment processing handles network errors gracefully."""
    with patch('payment_gateway.charge') as mock_charge:
        mock_charge.side_effect = requests.ConnectionError("Network unreachable")
        
        with pytest.raises(PaymentError) as exc_info:
            process_payment(100.0, "credit_card")
            
        assert exc_info.value.error_code == "PAYMENT_GATEWAY_ERROR"
        assert "Network unreachable" in str(exc_info.value.context["gateway_error"])

def test_retry_mechanism_success_on_second_attempt():
    """Test retry logic succeeds after initial failure."""
    call_count = 0
    
    def flaky_function():
        nonlocal call_count
        call_count += 1
        if call_count == 1:
            raise requests.Timeout("Request timed out")
        return "success"
    
    result = retry_with_backoff(flaky_function, max_attempts=3)
    assert result == "success"
    assert call_count == 2
```

## Monitoring and Observability

### Error Metrics
Track error patterns to identify system issues:
- **Error Rate**: Percentage of operations that fail
- **Error Types**: Distribution of different error categories
- **Recovery Success**: How often retry logic succeeds
- **Error Duration**: How long errors persist

### Alerting Strategy
```python
def should_alert(error: Exception, context: dict) -> bool:
    """Determine if error should trigger an alert."""
    # Critical system errors always alert
    if isinstance(error, SystemCriticalError):
        return True
    
    # High frequency of user errors might indicate a system issue
    error_rate = get_recent_error_rate(type(error))
    if error_rate > 0.05:  # 5% error rate threshold
        return True
    
    # External service errors during business hours
    if isinstance(error, ExternalServiceError) and is_business_hours():
        return True
        
    return False
```

## Anti-patterns to Avoid

- **Silent Failures**: Catching exceptions without appropriate handling
- **Generic Exception Handling**: Catching all exceptions with same logic
- **Error Swallowing**: Losing important error information
- **Premature Recovery**: Retrying operations that will always fail
- **Error Message Leakage**: Exposing sensitive information in error messages
- **No Error Context**: Providing insufficient information for debugging

## Key Benefits

### System Reliability
- **Predictable Behavior**: Systems handle errors consistently
- **Reduced Downtime**: Graceful degradation keeps systems operational
- **Faster Recovery**: Clear error information enables quick fixes
- **Better User Experience**: Meaningful error messages help users succeed

### Development Efficiency
- **Easier Debugging**: Rich error context speeds problem resolution
- **Improved Testing**: Error scenarios are explicitly tested
- **Better Monitoring**: Structured error handling enables better observability
- **Reduced Support Load**: Clear error messages reduce support requests

# Problem Decomposition Patterns

## Core Principle

Problem decomposition involves breaking complex challenges into smaller, manageable components that can be understood, solved, and verified independently while maintaining awareness of their relationships and interactions.

## When to Apply

- Large, overwhelming problems that seem intractable
- Requirements that are vague or constantly changing
- Technical challenges spanning multiple domains
- Projects involving multiple teams or stakeholders
- Debugging complex, multi-layered issues

## Decomposition Strategies

### 1. Hierarchical Decomposition
Break problems into levels of increasing detail:

```
Application Slow → 
├── Frontend Performance
│   ├── Bundle Size
│   ├── Rendering Speed
│   └── Asset Loading
├── Backend Performance  
│   ├── API Response Time
│   ├── Database Queries
│   └── Server Resources
└── Infrastructure
    ├── Network Latency
    ├── CDN Configuration
    └── Server Capacity
```

### 2. Functional Decomposition
Separate by what the system needs to do:

```
E-commerce Platform →
├── User Management (auth, profiles, preferences)
├── Product Catalog (search, display, inventory)
├── Shopping Cart (add, modify, persistence)
├── Payment Processing (validation, transactions, receipts)
├── Order Management (tracking, fulfillment, returns)
└── Analytics (user behavior, sales data, reports)
```

### 3. Domain-Driven Decomposition
Organize by business domains and their boundaries:

```
Healthcare System →
├── Patient Management Domain
├── Appointment Scheduling Domain  
├── Medical Records Domain
├── Billing and Insurance Domain
├── Pharmacy Management Domain
└── Reporting and Analytics Domain
```

### 4. Temporal Decomposition
Break down by when things happen:

```
User Registration Flow →
├── Pre-Registration (marketing, landing page)
├── Registration Process (form, validation, verification)
├── Initial Setup (profile creation, preferences)
├── Onboarding (tutorials, first actions)
└── Post-Registration (engagement, retention)
```

### 5. Risk-Based Decomposition
Separate by uncertainty and complexity:

```
Migration Project →
├── High Risk/High Impact
│   ├── Data migration strategy
│   └── Authentication system changes
├── Medium Risk/High Impact
│   ├── API endpoint updates
│   └── Database schema changes
├── Low Risk/High Impact
│   ├── UI updates
│   └── Configuration changes
└── Low Risk/Low Impact
    ├── Documentation updates
    └── Monitoring adjustments
```

## Decomposition Process

### Phase 1: Initial Breakdown
1. **State the problem clearly** in one sentence
2. **Identify major components** - aim for 3-7 main parts
3. **Define boundaries** between components
4. **List assumptions** about each component
5. **Note interdependencies** between parts

### Phase 2: Iterative Refinement
1. **Examine each component** - can it be broken down further?
2. **Look for patterns** - are similar problems grouped together?
3. **Check completeness** - does the sum cover the whole problem?
4. **Validate boundaries** - are the divisions logical and workable?
5. **Prioritize components** by impact, risk, and dependencies

### Phase 3: Integration Planning
1. **Map dependencies** between components
2. **Identify integration points** where components interact
3. **Plan coordination** mechanisms between parts
4. **Define success criteria** for each component and the whole
5. **Create feedback loops** to detect when assumptions change

## Examples

### Example 1: API Performance Problem

**Initial Problem**: "API is too slow"

**Decomposition**:
```
API Performance →
├── Request Processing
│   ├── Route matching speed
│   ├── Middleware overhead
│   └── Request validation time
├── Business Logic
│   ├── Algorithm efficiency
│   ├── External service calls
│   └── Computation complexity
├── Data Access
│   ├── Database query performance
│   ├── Connection pool management
│   └── Cache hit rates
└── Response Generation
    ├── Serialization speed
    ├── Response size
    └── Compression efficiency
```

**Integration Considerations**:
- Database optimizations might affect business logic assumptions
- Caching changes could impact data consistency requirements
- Response format changes might affect client applications

### Example 2: Team Productivity Problem

**Initial Problem**: "Development team is moving too slowly"

**Decomposition**:
```
Team Productivity →
├── Process Issues
│   ├── Meeting overhead
│   ├── Code review bottlenecks
│   └── Deployment friction
├── Technical Issues
│   ├── Legacy code complexity
│   ├── Testing infrastructure
│   └── Development environment setup
├── Communication Issues
│   ├── Requirements clarity
│   ├── Cross-team coordination
│   └── Knowledge sharing
└── Resource Issues
    ├── Team capacity
    ├── Skill gaps
    └── Tool limitations
```

## Quality Checks

### Completeness Check
- **Coverage**: Do all components together solve the original problem?
- **Gaps**: Are there aspects of the problem not addressed?
- **Overlap**: Are responsibilities clearly separated?

### Feasibility Check
- **Size**: Is each component small enough to understand and solve?
- **Skills**: Do we have the expertise to address each component?
- **Resources**: Are the components achievable with available resources?

### Dependency Check
- **Prerequisites**: What must be completed before each component?
- **Blockers**: Which components might prevent others from succeeding?
- **Coordination**: How will components work together?

## Tools and Techniques

### Mind Mapping
- Visual representation of problem structure
- Shows relationships and hierarchies clearly
- Helps identify missing components
- Good for brainstorming and initial decomposition

### Work Breakdown Structure (WBS)
- Formal project management technique
- Organizes work into deliverable components
- Includes effort estimation and scheduling
- Good for project planning and tracking

### System Context Diagrams
- Shows system boundaries and external interfaces
- Identifies stakeholders and external dependencies
- Helps understand scope and constraints
- Good for complex systems with many interactions

### Dependency Matrices
- Maps relationships between components
- Identifies critical path and bottlenecks
- Shows coordination requirements
- Good for understanding integration complexity

## Anti-patterns to Avoid

- **Over-Decomposition**: Breaking things down beyond useful granularity
- **Under-Decomposition**: Components still too complex to handle effectively
- **Arbitrary Boundaries**: Divisions that don't reflect natural problem structure
- **Ignoring Dependencies**: Treating components as if they're completely independent
- **Static Decomposition**: Not updating breakdown as understanding evolves
- **Perfect Decomposition Fallacy**: Spending too much time on perfect structure instead of starting work

## Benefits

- **Cognitive Load Reduction**: Smaller problems are easier to understand and solve
- **Parallel Work**: Independent components can be worked on simultaneously
- **Risk Mitigation**: Problems in one component don't necessarily affect others
- **Progress Tracking**: Completion of components provides measurable progress
- **Expertise Matching**: Different components can be assigned to appropriate specialists
- **Testing and Validation**: Components can be verified independently before integration